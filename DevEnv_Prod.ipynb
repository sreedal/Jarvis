{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prod Version of DevEnv**\n",
    "\n",
    "**This notebook is run using nbconvert after devenv service starts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting twitter\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/e2/f602e3f584503f03e0389491b251464f8ecfe2596ac86e6b9068fe7419d3/twitter-1.18.0-py2.py3-none-any.whl (54kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 791kB/s eta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: twitter\n",
      "Successfully installed twitter-1.18.0\n",
      "Collecting feedparser\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/d8/7d37fec71ff7c9dbcdd80d2b48bcdd86d6af502156fc93846fb0102cb2c4/feedparser-5.2.1.tar.bz2 (192kB)\n",
      "\u001b[K     |████████████████████████████████| 194kB 1.2MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: feedparser\n",
      "  Building wheel for feedparser (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for feedparser: filename=feedparser-5.2.1-cp37-none-any.whl size=44940 sha256=f77314c234badb8325fd396e9f479a5269b998a1ffe62d5897bd602c051027eb\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/8c/69/b7/f52763c41c5471df57703a0ef718a32a5e81ee35dcf6d4f97f\n",
      "Successfully built feedparser\n",
      "Installing collected packages: feedparser\n",
      "Successfully installed feedparser-5.2.1\n",
      "Collecting schedule\n",
      "  Downloading https://files.pythonhosted.org/packages/57/22/3a709462eb02412bd1145f6e53604f36bba191e3e4e397bea4a718fec38c/schedule-0.6.0-py2.py3-none-any.whl\n",
      "Installing collected packages: schedule\n",
      "Successfully installed schedule-0.6.0\n",
      "Collecting kafka-python\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/c9/9863483a1353700ba87821b4f39085eb18fd1bcbb1e954c697177d67f03f/kafka_python-1.4.7-py2.py3-none-any.whl (266kB)\n",
      "\u001b[K     |████████████████████████████████| 266kB 1.5MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: kafka-python\n",
      "Successfully installed kafka-python-1.4.7\n",
      "Collecting redis\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/ae/28613a62eea0d53d3db3147f8715f90da07667e99baeedf1010eb400f8c0/redis-3.3.11-py2.py3-none-any.whl (66kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 1.4MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: redis\n",
      "Successfully installed redis-3.3.11\n"
     ]
    }
   ],
   "source": [
    "!pip install twitter\n",
    "!pip install feedparser\n",
    "!pip install schedule\n",
    "!pip install kafka-python\n",
    "!pip install redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from json import dumps, loads, load\n",
    "from kafka import KafkaProducer\n",
    "from datetime import datetime, timedelta\n",
    "from feedparser import parse\n",
    "from urllib.request import urlopen\n",
    "from twitter import Twitter\n",
    "import schedule\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = [\"MSFT\",\"AAPL\"]\n",
    "feeds = [\"http://feeds.reuters.com/reuters/businessNews\"]\n",
    "\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=['broker:9092'],\n",
    "    api_version= (0,11),\n",
    "    value_serializer=lambda x: dumps(x).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DownloadStreams():\n",
    "    # Yahoo Finance Stream for Stock Price\n",
    "    f_data = {}\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            y_finance = load(urlopen(\"https://query1.finance.yahoo.com/v7/finance/chart/\"+ticker+\"?range=1h&interval=1h\"))\n",
    "            meta = y_finance['chart']['result'][0]['meta']\n",
    "            timestamp = meta['regularMarketTime']\n",
    "            price = meta['regularMarketPrice']\n",
    "            f_data[ticker] = {\"Type\": \"Finance\", \"Ticker\": ticker, \"Timestamp\":timestamp, \"Price\":price}\n",
    "        except:\n",
    "            print(\"Exception in Download Stream for \"+ticker)\n",
    "    \n",
    "    # News Stream from Reuters for Business\n",
    "    feed_data = {}\n",
    "    for feed in feeds:\n",
    "        feed_data[feed] = [{\"Type\": \"News\", \"Timestamp\": datetime.timestamp(datetime.now()), \"Title\":l.title, \"Summary\":l.summary, \"Link\":l.link} for l in (parse(feed))[\"entries\"]]\n",
    "        # print([l.title for l in d[\"entries\"]])\n",
    "\n",
    "    return f_data, feed_data\n",
    "\n",
    "def UploadStreamsToKafka(f_data, feed_data):\n",
    "    for key in f_data.keys():\n",
    "        producer.send('finance_ticker', value=f_data[key])\n",
    "    for key in feed_data.keys():\n",
    "        for entry in feed_data[key]:\n",
    "            producer.send('news_feed', value=entry)\n",
    "    producer.flush()\n",
    "\n",
    "def HourlyJob():\n",
    "    # Check, Download & Parse each stream\n",
    "    f_data, feed_data = DownloadStreams()\n",
    "    # Upload cleaned events into Kafka Topics\n",
    "    UploadStreamsToKafka(f_data, feed_data)\n",
    "    print(\"Hourly Run Events Complete - Sleeping now\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hourly Run Events Complete - Sleeping now\n"
     ]
    }
   ],
   "source": [
    "HourlyJob()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hourly Run Events Complete - Sleeping now\n"
     ]
    }
   ],
   "source": [
    "schedule.clear()\n",
    "HourlyJob()\n",
    "\n",
    "schedule.every(15).minutes.do(HourlyJob)\n",
    "starttime = datetime.now()\n",
    "endtime = starttime + timedelta(minutes=5)\n",
    "\n",
    "while True: #datetime.now()<endtime:\n",
    "    schedule.run_pending()\n",
    "    sleep(10)\n",
    "    \n",
    "schedule.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
